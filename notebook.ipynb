{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cervical Cancer Risk Prediction - Automated Machine Learning Pipeline\n",
    "# Import required libraries\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "# Data manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn modules\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import (LogisticRegression,SGDClassifier)\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, \n",
    "    AdaBoostClassifier, ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Imbalanced-learn modules\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "# Other machine learning libraries\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Loading and Initial Exploration\n",
    "# Import the csv file\n",
    "cancer_df = pd.read_csv('./data/risk_factors_cervical_cancer.csv')\n",
    "\n",
    "# Replace '?' with NaN\n",
    "cancer_df = cancer_df.replace('?', np.nan)\n",
    "\n",
    "# Convert all columns to numeric type\n",
    "cancer_df = cancer_df.apply(pd.to_numeric)\n",
    "\n",
    "# Drop columns with more than 80% missing values\n",
    "missing_threshold = 0.8\n",
    "cancer_df = cancer_df.dropna(thresh=missing_threshold * len(cancer_df), axis=1)\n",
    "\n",
    "# Impute remaining missing values with the mean\n",
    "cancer_df.fillna(cancer_df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Automated Feature Selection\n",
    "# Calculate the absolute correlation of features with the target variable\n",
    "abs_corr_with_target = cancer_df.corr()['Biopsy'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Keep features with absolute correlation greater than a threshold\n",
    "correlation_threshold = 0.05\n",
    "features_to_keep = abs_corr_with_target[abs_corr_with_target >= correlation_threshold].index\n",
    "cancer_df = cancer_df[features_to_keep]\n",
    "\n",
    "# Separate target and features\n",
    "target_df = cancer_df['Biopsy']\n",
    "input_df = cancer_df.drop(columns=['Biopsy'])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(input_df).astype('float32')\n",
    "y = np.array(target_df).astype('float32').reshape(-1, 1)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Handle Class Imbalance with SMOTE\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, Y_train_resampled = smote.fit_resample(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression with SMOTE...\n",
      "Logistic Regression - Accuracy: 0.9612, F1: 0.7059\n",
      "Training Random Forest with SMOTE...\n",
      "Random Forest - Accuracy: 0.9535, F1: 0.6250\n",
      "Training SGD SVM with SMOTE...\n",
      "SGD SVM - Accuracy: 0.9690, F1: 0.7500\n",
      "Training Gradient Boosting with SMOTE...\n",
      "Gradient Boosting - Accuracy: 0.9535, F1: 0.6250\n",
      "Training XGBoost with SMOTE...\n",
      "XGBoost - Accuracy: 0.9612, F1: 0.7059\n",
      "Training Neural Network with SMOTE...\n",
      "Neural Network - Accuracy: 0.9380, F1: 0.4286\n",
      "Training KNN with SMOTE...\n",
      "KNN - Accuracy: 0.9612, F1: 0.7059\n",
      "Training LightGBM with SMOTE...\n",
      "[LightGBM] [Info] Number of positive: 560, number of negative: 560\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 846\n",
      "[LightGBM] [Info] Number of data points in the train set: 1120, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM - Accuracy: 0.9612, F1: 0.7059\n",
      "Training CatBoost with SMOTE...\n",
      "CatBoost - Accuracy: 0.9612, F1: 0.7059\n",
      "Training AdaBoost with SMOTE...\n",
      "AdaBoost - Accuracy: 0.9612, F1: 0.7059\n",
      "Training Extra Trees with SMOTE...\n",
      "Extra Trees - Accuracy: 0.9457, F1: 0.5333\n",
      "Training Balanced Bagging with SMOTE...\n",
      "Balanced Bagging - Accuracy: 0.9690, F1: 0.7143\n",
      "\n",
      "Best Baseline Model: SGD SVM with F1 Score: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# 4. Automated Model Training and Evaluation\n",
    "def evaluate_model(model, X_train, X_test, Y_train, Y_test):\n",
    "    \"\"\"Evaluate a model and return performance metrics\"\"\"\n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, Y_train.ravel())\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(Y_test, y_pred)\n",
    "    precision = precision_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "    f1 = f1_score(Y_test, y_pred)\n",
    "    \n",
    "    # Calculate ROC AUC if the model has predict_proba\n",
    "    try:\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        roc_auc = roc_auc_score(Y_test, y_pred_proba)\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    \n",
    "    return {\n",
    "        'model': model.__class__.__name__,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'training_time': training_time,\n",
    "        'y_pred': y_pred\n",
    "    }\n",
    "\n",
    "# Initialize models with class weighting\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    'SGD SVM': SGDClassifier(loss='hinge', penalty='l2', max_iter=1000, tol=1e-3, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', \n",
    "                                 scale_pos_weight=np.sum(Y_train == 0) / np.sum(Y_train == 1), random_state=42),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'LightGBM': LGBMClassifier(class_weight='balanced', random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(silent=True, random_state=42),  # silent=True to suppress output\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'Extra Trees': ExtraTreesClassifier(class_weight='balanced', random_state=42),\n",
    "    'Balanced Bagging': BalancedBaggingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluate all baseline models on resampled data\n",
    "baseline_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} with SMOTE...\")\n",
    "    result = evaluate_model(model, X_train_resampled, X_val, Y_train_resampled, Y_val)\n",
    "    result['model'] = name\n",
    "    baseline_results.append(result)\n",
    "    print(f\"{name} - Accuracy: {result['accuracy']:.4f}, F1: {result['f1_score']:.4f}\")\n",
    "\n",
    "# Select the best baseline model\n",
    "best_baseline_model = max(baseline_results, key=lambda x: x['f1_score'])\n",
    "print(f\"\\nBest Baseline Model: {best_baseline_model['model']} with F1 Score: {best_baseline_model['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Logistic Regression...\n",
      "Best parameters for Logistic Regression: {'solver': 'liblinear', 'penalty': 'l1', 'C': 10}\n",
      "Best F1 score: 0.9515\n",
      "\n",
      "Tuning Random Forest...\n",
      "Best parameters for Random Forest: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\n",
      "Best F1 score: 0.9752\n",
      "\n",
      "Tuning SGD SVM...\n",
      "Best parameters for SGD SVM: {'penalty': 'l1', 'learning_rate': 'optimal', 'alpha': 0.001}\n",
      "Best F1 score: 0.9570\n",
      "\n",
      "Tuning Gradient Boosting...\n",
      "Best parameters for Gradient Boosting: {'subsample': 0.8, 'n_estimators': 200, 'min_samples_split': 10, 'max_depth': 3, 'learning_rate': 0.01}\n",
      "Best F1 score: 0.9751\n",
      "\n",
      "Tuning XGBoost...\n",
      "Best parameters for XGBoost: {'subsample': 0.9, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.2, 'colsample_bytree': 0.9}\n",
      "Best F1 score: 0.9736\n",
      "\n",
      "Tuning Neural Network...\n",
      "Best parameters for Neural Network: {'learning_rate': 'adaptive', 'hidden_layer_sizes': (100, 50), 'alpha': 0.001, 'activation': 'relu'}\n",
      "Best F1 score: 0.9762\n",
      "\n",
      "Tuning KNN...\n",
      "Best parameters for KNN: {'weights': 'distance', 'p': 1, 'n_neighbors': 3}\n",
      "Best F1 score: 0.9690\n",
      "\n",
      "Tuning LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 560, number of negative: 560\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 846\n",
      "[LightGBM] [Info] Number of data points in the train set: 1120, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters for LightGBM: {'num_leaves': 100, 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.2}\n",
      "Best F1 score: 0.9725\n",
      "\n",
      "Tuning CatBoost...\n",
      "Best parameters for CatBoost: {'learning_rate': 0.1, 'iterations': 200, 'depth': 5}\n",
      "Best F1 score: 0.9769\n",
      "\n",
      "Tuning AdaBoost...\n",
      "Best parameters for AdaBoost: {'n_estimators': 200, 'learning_rate': 0.2}\n",
      "Best F1 score: 0.9624\n",
      "\n",
      "Tuning Extra Trees...\n",
      "Best parameters for Extra Trees: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 20}\n",
      "Best F1 score: 0.9778\n",
      "\n",
      "Tuning Balanced Bagging...\n",
      "Best parameters for Balanced Bagging: {'n_estimators': 100, 'max_samples': 1.0, 'max_features': 0.7}\n",
      "Best F1 score: 0.9768\n"
     ]
    }
   ],
   "source": [
    "# 5. Automated Hyperparameter Tuning\n",
    "# Define hyperparameter grids for tuning\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SGD SVM': {\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1],  # Regularization strength\n",
    "        'penalty': ['l2', 'l1', 'elasticnet'],  # Type of regularization\n",
    "        'learning_rate': ['constant', 'optimal', 'adaptive'],  # Learning rate schedule\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    'Neural Network': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]  # 1: Manhattan, 2: Euclidean\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'num_leaves': [31, 50, 100]\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'iterations': [50, 100, 200],\n",
    "        'depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2]\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2]\n",
    "    },\n",
    "    'Extra Trees': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Balanced Bagging': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_samples': [0.5, 0.7, 1.0],\n",
    "        'max_features': [0.5, 0.7, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning for the top 3 models\n",
    "tuned_models = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTuning {model_name}...\")\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        model,\n",
    "        param_grids[model_name],\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        scoring='f1',\n",
    "        n_iter=20,\n",
    "        random_state=42\n",
    "    )\n",
    "    grid_search.fit(X_train_resampled, Y_train_resampled.ravel())\n",
    "    tuned_models[model_name] = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best F1 score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression...\n",
      "Logistic Regression - Accuracy: 0.9612, F1: 0.7059\n",
      "Evaluating Random Forest...\n",
      "Random Forest - Accuracy: 0.9457, F1: 0.5333\n",
      "Evaluating SGD SVM...\n",
      "SGD SVM - Accuracy: 0.9612, F1: 0.7059\n",
      "Evaluating Gradient Boosting...\n",
      "Gradient Boosting - Accuracy: 0.9612, F1: 0.7059\n",
      "Evaluating XGBoost...\n",
      "XGBoost - Accuracy: 0.9612, F1: 0.7059\n",
      "Evaluating Neural Network...\n",
      "Neural Network - Accuracy: 0.9535, F1: 0.5000\n",
      "Evaluating KNN...\n",
      "KNN - Accuracy: 0.9457, F1: 0.5333\n",
      "Evaluating LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 560, number of negative: 560\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 846\n",
      "[LightGBM] [Info] Number of data points in the train set: 1120, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM - Accuracy: 0.9612, F1: 0.7059\n",
      "Evaluating CatBoost...\n",
      "CatBoost - Accuracy: 0.9612, F1: 0.7059\n",
      "Evaluating AdaBoost...\n",
      "AdaBoost - Accuracy: 0.9612, F1: 0.7059\n",
      "Evaluating Extra Trees...\n",
      "Extra Trees - Accuracy: 0.9535, F1: 0.5714\n",
      "Evaluating Balanced Bagging...\n",
      "Balanced Bagging - Accuracy: 0.9690, F1: 0.7143\n",
      "\n",
      "Best Model Overall: SGD SVM with F1 Score: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# 6. Evaluate Tuned Models\n",
    "tuned_results = []\n",
    "for name, model in tuned_models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    result = evaluate_model(model, X_train_resampled, X_val, Y_train_resampled, Y_val)\n",
    "    result['model'] = name\n",
    "    tuned_results.append(result)\n",
    "    print(f\"{name} - Accuracy: {result['accuracy']:.4f}, F1: {result['f1_score']:.4f}\")\n",
    "\n",
    "# Select the best model overall\n",
    "final_results = baseline_results + tuned_results\n",
    "best_model_result = max(final_results, key=lambda x: x['f1_score'])\n",
    "best_model_name = best_model_result['model']\n",
    "best_model = tuned_models.get(best_model_name, models[best_model_name])\n",
    "\n",
    "print(f\"\\nBest Model Overall: {best_model_name} with F1 Score: {best_model_result['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model saved to: model_artifacts/cervical_cancer_best_model.joblib\n",
      "Scaler saved to: model_artifacts/cervical_cancer_scaler.joblib\n",
      "Feature names saved to: model_artifacts/feature_names.joblib\n"
     ]
    }
   ],
   "source": [
    "# 7. Save the Best Model and Artifacts\n",
    "import os\n",
    "os.makedirs('model_artifacts', exist_ok=True)\n",
    "\n",
    "# Save the best model\n",
    "model_filename = f'model_artifacts/cervical_cancer_best_model.joblib'\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"\\nBest model saved to: {model_filename}\")\n",
    "\n",
    "# Save the scaler\n",
    "scaler_filename = 'model_artifacts/cervical_cancer_scaler.joblib'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"Scaler saved to: {scaler_filename}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names_filename = 'model_artifacts/feature_names.joblib'\n",
    "joblib.dump(list(input_df.columns), feature_names_filename)\n",
    "print(f\"Feature names saved to: {feature_names_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model on 1249 samples...\n",
      "\n",
      "Final Test Set Evaluation:\n",
      "Model: SGD SVM\n",
      "Test Accuracy: 0.9457\n",
      "Test Precision: 0.5385\n",
      "Test Recall: 0.8750\n",
      "Test F1 Score: 0.6667\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.95      0.97       121\n",
      "         1.0       0.54      0.88      0.67         8\n",
      "\n",
      "    accuracy                           0.95       129\n",
      "   macro avg       0.76      0.91      0.82       129\n",
      "weighted avg       0.96      0.95      0.95       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. Final Evaluation on Test Set\n",
    "# Fit the best model on the combined training and validation data\n",
    "X_train_full = np.vstack((X_train_resampled, X_val))\n",
    "Y_train_full = np.vstack((Y_train_resampled.reshape(-1, 1), Y_val))\n",
    "\n",
    "print(f\"Training final model on {X_train_full.shape[0]} samples...\")\n",
    "best_model.fit(X_train_full, Y_train_full.ravel())\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate final metrics\n",
    "final_accuracy = accuracy_score(Y_test, test_predictions)\n",
    "final_precision = precision_score(Y_test, test_predictions)\n",
    "final_recall = recall_score(Y_test, test_predictions)\n",
    "final_f1 = f1_score(Y_test, test_predictions)\n",
    "\n",
    "print(\"\\nFinal Test Set Evaluation:\")\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Test Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {final_precision:.4f}\")\n",
    "print(f\"Test Recall: {final_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {final_f1:.4f}\")\n",
    "\n",
    "# Define plot_confusion_matrix function\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "# Plot final confusion matrix\n",
    "plot_confusion_matrix(Y_test, test_predictions, f\"Final Model - {best_model_name}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(Y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cervical Cancer Risk Prediction Model Summary ===\n",
      "Best model: SGD SVM\n",
      "Test set accuracy: 0.9457\n",
      "Test set F1 score: 0.6667\n",
      "Test set precision: 0.5385\n",
      "Test set recall: 0.8750\n",
      "\n",
      "Notebook completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# 9. Summary and Conclusions\n",
    "print(\"\\n=== Cervical Cancer Risk Prediction Model Summary ===\")\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Test set accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Test set F1 score: {final_f1:.4f}\")\n",
    "print(f\"Test set precision: {final_precision:.4f}\")\n",
    "print(f\"Test set recall: {final_recall:.4f}\")\n",
    "\n",
    "# %%\n",
    "# End of notebook\n",
    "print(\"\\nNotebook completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
