{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cervical Cancer Risk Prediction - Automated Machine Learning Pipeline\n",
    "# Import required libraries\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "# Data manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn modules\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier, \n",
    "    AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Imbalanced-learn modules\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "# Other machine learning libraries\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Loading and Initial Exploration\n",
    "# Import the csv file\n",
    "cancer_df = pd.read_csv('./data/risk_factors_cervical_cancer.csv')\n",
    "\n",
    "# Replace '?' with NaN\n",
    "cancer_df = cancer_df.replace('?', np.nan)\n",
    "\n",
    "# Convert all columns to numeric type\n",
    "cancer_df = cancer_df.apply(pd.to_numeric)\n",
    "\n",
    "# Drop columns with more than 80% missing values\n",
    "missing_threshold = 0.8\n",
    "cancer_df = cancer_df.dropna(thresh=missing_threshold * len(cancer_df), axis=1)\n",
    "\n",
    "# Impute remaining missing values with the mean\n",
    "cancer_df.fillna(cancer_df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Automated Feature Selection\n",
    "# Calculate the absolute correlation of features with the target variable\n",
    "abs_corr_with_target = cancer_df.corr()['Biopsy'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Keep features with absolute correlation greater than a threshold\n",
    "correlation_threshold = 0.05\n",
    "features_to_keep = abs_corr_with_target[abs_corr_with_target >= correlation_threshold].index\n",
    "cancer_df = cancer_df[features_to_keep]\n",
    "\n",
    "# Separate target and features\n",
    "target_df = cancer_df['Biopsy']\n",
    "input_df = cancer_df.drop(columns=['Biopsy'])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(input_df).astype('float32')\n",
    "y = np.array(target_df).astype('float32').reshape(-1, 1)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Handle Class Imbalance with SMOTE\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, Y_train_resampled = smote.fit_resample(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression with SMOTE...\n",
      "Logistic Regression - Accuracy: 0.9612, F1: 0.7059\n",
      "Training Random Forest with SMOTE...\n",
      "Random Forest - Accuracy: 0.9535, F1: 0.6250\n",
      "Training SVM with SMOTE...\n",
      "SVM - Accuracy: 0.9612, F1: 0.7059\n",
      "Training Gradient Boosting with SMOTE...\n",
      "Gradient Boosting - Accuracy: 0.9535, F1: 0.6250\n",
      "Training XGBoost with SMOTE...\n",
      "XGBoost - Accuracy: 0.9612, F1: 0.7059\n",
      "Training Neural Network with SMOTE...\n",
      "Neural Network - Accuracy: 0.9380, F1: 0.4286\n",
      "Training KNN with SMOTE...\n",
      "KNN - Accuracy: 0.9612, F1: 0.7059\n",
      "Training LightGBM with SMOTE...\n",
      "[LightGBM] [Info] Number of positive: 560, number of negative: 560\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 846\n",
      "[LightGBM] [Info] Number of data points in the train set: 1120, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM - Accuracy: 0.9612, F1: 0.7059\n",
      "Training CatBoost with SMOTE...\n",
      "CatBoost - Accuracy: 0.9612, F1: 0.7059\n",
      "Training AdaBoost with SMOTE...\n",
      "AdaBoost - Accuracy: 0.9612, F1: 0.7059\n",
      "Training Extra Trees with SMOTE...\n",
      "Extra Trees - Accuracy: 0.9457, F1: 0.5333\n",
      "Training Balanced Bagging with SMOTE...\n",
      "Balanced Bagging - Accuracy: 0.9690, F1: 0.7143\n",
      "\n",
      "Best Baseline Model: Balanced Bagging with F1 Score: 0.7143\n"
     ]
    }
   ],
   "source": [
    "# 4. Automated Model Training and Evaluation\n",
    "def evaluate_model(model, X_train, X_test, Y_train, Y_test):\n",
    "    \"\"\"Evaluate a model and return performance metrics\"\"\"\n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, Y_train.ravel())\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(Y_test, y_pred)\n",
    "    precision = precision_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "    f1 = f1_score(Y_test, y_pred)\n",
    "    \n",
    "    # Calculate ROC AUC if the model has predict_proba\n",
    "    try:\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        roc_auc = roc_auc_score(Y_test, y_pred_proba)\n",
    "    except:\n",
    "        roc_auc = None\n",
    "    \n",
    "    return {\n",
    "        'model': model.__class__.__name__,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'training_time': training_time,\n",
    "        'y_pred': y_pred\n",
    "    }\n",
    "\n",
    "# Initialize models with class weighting\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    'SVM': SVC(probability=True, class_weight='balanced', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', \n",
    "                                 scale_pos_weight=np.sum(Y_train == 0) / np.sum(Y_train == 1), random_state=42),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'LightGBM': LGBMClassifier(class_weight='balanced', random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(silent=True, random_state=42),  # silent=True to suppress output\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'Extra Trees': ExtraTreesClassifier(class_weight='balanced', random_state=42),\n",
    "    'Balanced Bagging': BalancedBaggingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluate all baseline models on resampled data\n",
    "baseline_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} with SMOTE...\")\n",
    "    result = evaluate_model(model, X_train_resampled, X_val, Y_train_resampled, Y_val)\n",
    "    result['model'] = name\n",
    "    baseline_results.append(result)\n",
    "    print(f\"{name} - Accuracy: {result['accuracy']:.4f}, F1: {result['f1_score']:.4f}\")\n",
    "\n",
    "# Select the best baseline model\n",
    "best_baseline_model = max(baseline_results, key=lambda x: x['f1_score'])\n",
    "print(f\"\\nBest Baseline Model: {best_baseline_model['model']} with F1 Score: {best_baseline_model['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Logistic Regression...\n"
     ]
    }
   ],
   "source": [
    "# 5. Automated Hyperparameter Tuning\n",
    "# Define hyperparameter grids for tuning\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    'Neural Network': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]  # 1: Manhattan, 2: Euclidean\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'num_leaves': [31, 50, 100]\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'iterations': [50, 100, 200],\n",
    "        'depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2]\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2]\n",
    "    },\n",
    "    'Extra Trees': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Balanced Bagging': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_samples': [0.5, 0.7, 1.0],\n",
    "        'max_features': [0.5, 0.7, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning for the top 3 models\n",
    "tuned_models = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTuning {model_name}...\")\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        model,\n",
    "        param_grids[model_name],\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        scoring='f1',\n",
    "        n_iter=20,\n",
    "        random_state=42\n",
    "    )\n",
    "    grid_search.fit(X_train_resampled, Y_train_resampled.ravel())\n",
    "    tuned_models[model_name] = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best F1 score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluate Tuned Models\n",
    "tuned_results = []\n",
    "for name, model in tuned_models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    result = evaluate_model(model, X_train_resampled, X_val, Y_train_resampled, Y_val)\n",
    "    result['model'] = name\n",
    "    tuned_results.append(result)\n",
    "    print(f\"{name} - Accuracy: {result['accuracy']:.4f}, F1: {result['f1_score']:.4f}\")\n",
    "\n",
    "# Select the best model overall\n",
    "final_results = baseline_results + tuned_results\n",
    "best_model_result = max(final_results, key=lambda x: x['f1_score'])\n",
    "best_model_name = best_model_result['model']\n",
    "best_model = tuned_models.get(best_model_name, models[best_model_name])\n",
    "\n",
    "print(f\"\\nBest Model Overall: {best_model_name} with F1 Score: {best_model_result['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Save the Best Model and Artifacts\n",
    "import os\n",
    "os.makedirs('model_artifacts', exist_ok=True)\n",
    "\n",
    "# Save the best model\n",
    "model_filename = f'model_artifacts/cervical_cancer_best_model.joblib'\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"\\nBest model saved to: {model_filename}\")\n",
    "\n",
    "# Save the scaler\n",
    "scaler_filename = 'model_artifacts/cervical_cancer_scaler.joblib'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"Scaler saved to: {scaler_filename}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names_filename = 'model_artifacts/feature_names.joblib'\n",
    "joblib.dump(list(input_df.columns), feature_names_filename)\n",
    "print(f\"Feature names saved to: {feature_names_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Final Evaluation on Test Set\n",
    "# Fit the best model on the combined training and validation data\n",
    "X_train_full = np.vstack((X_train_resampled, X_val))\n",
    "Y_train_full = np.vstack((Y_train_resampled.reshape(-1, 1), Y_val))\n",
    "\n",
    "print(f\"Training final model on {X_train_full.shape[0]} samples...\")\n",
    "best_model.fit(X_train_full, Y_train_full.ravel())\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Calculate final metrics\n",
    "final_accuracy = accuracy_score(Y_test, test_predictions)\n",
    "final_precision = precision_score(Y_test, test_predictions)\n",
    "final_recall = recall_score(Y_test, test_predictions)\n",
    "final_f1 = f1_score(Y_test, test_predictions)\n",
    "\n",
    "print(\"\\nFinal Test Set Evaluation:\")\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Test Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {final_precision:.4f}\")\n",
    "print(f\"Test Recall: {final_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {final_f1:.4f}\")\n",
    "\n",
    "# Define plot_confusion_matrix function\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "# Plot final confusion matrix\n",
    "plot_confusion_matrix(Y_test, test_predictions, f\"Final Model - {best_model_name}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(Y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Summary and Conclusions\n",
    "print(\"\\n=== Cervical Cancer Risk Prediction Model Summary ===\")\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Test set accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Test set F1 score: {final_f1:.4f}\")\n",
    "print(f\"Test set precision: {final_precision:.4f}\")\n",
    "print(f\"Test set recall: {final_recall:.4f}\")\n",
    "\n",
    "# %%\n",
    "# End of notebook\n",
    "print(\"\\nNotebook completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
